# ğŸ’° Smart Spend - Intelligent Personal Finance Manager

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.122.0-brightgreen?logo=fastapi)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Async-blue?logo=postgresql)](https://www.postgresql.org/)
[![Redis](https://img.shields.io/badge/Redis-5.3.1-red?logo=redis)](https://redis.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**Smart Spend** is an intelligent, AI-powered personal finance management system that automatically categorizes bank transactions, learns from user corrections, and provides personalized financial advice. Built with **FastAPI**, **PostgreSQL**, **Redis**, and **HuggingFace AI models**, it is designed for scalability, security, and privacy.

---

## ğŸ“Œ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Key Technologies & Design Decisions](#key-technologies--design-decisions)
- [Architecture](#architecture)
- [AI/ML Components](#aiml-components)
- [Database Schema](#database-schema)
- [API Endpoints](#api-endpoints)
- [Setup](#setup)
- [Usage](#usage)
- [Testing](#testing)
- [Deployment](#deployment)
- [Security Features](#security-features)
- [License](#license)
- [Contributing](#contributing)
- [Contact](#contact)

---

## ğŸ“– Overview

Smart Spend is a production-grade financial management application that processes bank statement CSVs, automatically categorizes transactions using AI, and provides actionable financial insights. The system uses a **two-tier categorization system** (rule-based + AI fallback), **learns from user corrections**, and offers **personalized financial coaching** powered by large language models.

### Key Capabilities
- ğŸ“„ **CSV Upload & Processing** â€“ Flexible column mapping for various bank statement formats  
- ğŸ¤– **AI-Powered Categorization** â€“ Zero-shot classification for immediate, accurate grouping  
- ğŸ’¡ **Learning from User Input** â€“ User corrections automatically create new, high-priority categorization rules  
- ğŸ’¬ **Personalized Coaching** â€“ LLM-powered insights based on spending habits  
- ğŸ”’ **Privacy-First Design** â€“ PII is sanitized before being sent to external AI services  

---

## âœ¨ Features

### Core Functionality
- **User Authentication**: Secure registration and login with JWTs and Argon2 password hashing  
- **Transaction Management**: Full CRUD operations for all user transactions  
- **Rule Management**: Create and manage custom categorization rules  
- **Dashboard**: Visualization of spending trends and category distribution  
- **Asynchronous Processing**: CSV processing runs in the background for a smooth user experience  

---

## ğŸ› ï¸ Key Technologies & Design Decisions

| Technology          | Purpose                  | Design Decision |
|-------------------|-------------------------|----------------|
| FastAPI            | API Framework           | High performance, async support, automatic OpenAPI/Swagger documentation |
| PostgreSQL         | Primary Database        | Robust, transactional, and scalable data persistence |
| SQLAlchemy (Async) | ORM                     | Type-safe, asynchronous database interaction |
| Redis / ARQ        | Cache & Queue           | Used for JWT blocklist cache and background job processing (CSV uploads) |
| Pandas             | Data Processing         | Efficient CSV standardization and mapping |
| HuggingFace        | AI Categorization       | Zero-shot model used for fast, general-purpose text categorization |
| Docker Compose     | Development Setup       | Easy setup for API, database, cache, and worker services |

---

## ğŸ—ï¸ Architecture

Smart Spend separates **synchronous I/O-bound API handling** and **asynchronous background processing** using ARQ + Redis for CPU/network-bound tasks. This ensures a responsive API while processing large CSVs efficiently.

### Request Flow (CSV Upload)
1. Client uploads CSV via `/upload/`  
2. FastAPI authenticates the user (JWT) and performs initial CSV parsing with Pandas  
3. Transaction data is enqueued as a `process_csv_job` in Redis  
4. Job ID is immediately returned to the client  
5. ARQ worker picks up the job asynchronously  
6. PII is sanitized before categorization  
7. Categorization occurs:  
   - **Tier 1 (Rule-Based)** â€“ checks existing user rules  
   - **Tier 2 (AI Fallback)** â€“ calls HuggingFace zero-shot classifier if no rule matches  
8. Categorized transactions are persisted in PostgreSQL  
9. Client can poll job status via `/jobs/{job_id}`  

---

## ğŸ¤– AI/ML Components

| Component                | Technology                     | Logic |
|--------------------------|--------------------------------|-------|
| Transaction Categorization | HuggingFace Inference API (Zero-Shot) | Classifies sanitized transaction descriptions; fallback to "Uncategorized" if unavailable |
| Financial Coaching       | OpenAI-compatible API          | Generates personalized insights from monthly spending data |
| PII Redaction Strategy   | Custom Python Logic/RegEx      | Sanitizes sensitive information via `sanitize_description()` |

---

smart-spend/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ woorkflows
â”‚       â””â”€â”€ ci.yml
â”‚
â”œâ”€â”€ smart-spend-backend/
â”‚   â”‚
â”‚   â”œâ”€â”€ docs/                                 # Backend documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                           # FastAPI app initialization & route registration
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                             # Core infrastructure
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                     # Settings management (Pydantic Settings)
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py                   # Async SQLAlchemy engine & session factory
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py               # FastAPI dependencies (auth, DB sessions)
â”‚   â”‚   â”‚   â”œâ”€â”€ logging_config.py
â”‚   â”‚   â”‚   â””â”€â”€ security.py                   # Password hashing, JWT creation/validation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                           # SQLAlchemy ORM models
â”‚   â”‚   â”‚   â””â”€â”€ models.py                     # User, Transaction, CategoryRule models
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ schemas/                          # Pydantic request/response models
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py                    # Validation schemas for all endpoints
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routers/                          # API route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                       # Registration, login, session validation
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py                     # CSV upload & job enqueueing
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py                       # Job status polling
â”‚   â”‚   â”‚   â””â”€â”€ transactions.py               # Transaction CRUD, dashboard, AI coach
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ services/                         # Business logic & external integrations
â”‚   â”‚       â”œâ”€â”€ ai_service.py                 # HuggingFace API calls, PII sanitization
â”‚   â”‚       â””â”€â”€ worker.py                     # Background CSV processing job
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ integration
â”‚   â”‚   â”‚   â””â”€â”€ test_e2e.py
â”‚   â”‚   â”œâ”€â”€ unit
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ai_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_category_overwrite.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_jobs.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_transactions.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_upload.py
â”‚   â”‚   â”‚   â””â”€â”€ test_worker.py
â”‚   â”‚   â”œâ”€â”€ conftest.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ .venv/
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic/                              # Database migrations
â”‚   â”‚   â”œâ”€â”€ versions/                         # Migration scripts
â”‚   â”‚   â””â”€â”€ env.py                            # Alembic configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ .flake8
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ pytest.ini
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ entrypoint_migrate_and_run.sh
â”‚   â”œâ”€â”€ arq_worker.py                         # ARQ worker configuration
â”‚   â”œâ”€â”€ alembic.ini                           # Alembic settings
â”‚   â”œâ”€â”€ requirements.txt                      # Python dependencies
â”‚   â”œâ”€â”€ .env.template
â”‚   â””â”€â”€ .env                                  # Environment variables (not in Git)
â”‚
â”œâ”€â”€ smart-spend-frontend/                     # currently empty
â”œâ”€â”€ .env
â”œâ”€â”€ .env.template
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ git_branching_strategy.md
â””â”€â”€ test_trandactions.csv                      # Example csv file for testing (Optional)

---

## ğŸš€ Setup (Docker Compose)

1. **Clone Repository**
```bash
git clone -b main https://github.com/Murci20965/smart-spend.git
cd smart-spend
```

2. **Create Development Branch**
```bash
git checkout -b dev
```

3. **Configure Environment**
```bash
cp smart-spend-backend/.env.template smart-spend-backend/.env
# Add HF_TOKEN if AI features are needed
```

4. **Start Services & Run Migrations**
```bash
docker compose up --build -d
# Alembic migrations run automatically via entrypoint_migrate_and_run.sh
```

5. **Access**
- API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)  
- Adminer: [http://localhost:8080](http://localhost:8080)  

6. **Stop Services**
```bash
docker compose down
```

---

## ğŸ’» Usage

### Development (Without Docker)
```bash
# Run PostgreSQL & Redis locally
uvicorn app.main:app --reload
# Start ARQ worker
arq arq_worker.WorkerSettings
```

### Production
- Use Docker Compose or orchestrator (e.g., Kubernetes, systemd) for persistent services  

---

## ğŸ§ª Testing
```bash
# Run all tests
docker compose run --rm api pytest -q

# With coverage report
docker compose run --rm api pytest --cov=app --cov-report=html
```

---

## ğŸ“¦ Deployment
- Separate `.env` files per environment  
- Enable SSL/TLS via reverse proxy  
- Configure CORS securely  
- Ensure database pooling  
- Always run migrations: `alembic upgrade head`  
- Scale API and worker services independently  

---

## ğŸ”’ Security Features
- **Passwords**: Argon2 hashing  
- **Authentication**: JWT with Redis blocklist  
- **PII Redaction**: Masked before external API calls  
- **Input Validation**: Pydantic schemas  
- **Data Isolation**: User data scoped by Foreign Keys  

---

## ğŸ“ License
MIT License  

---

## ğŸ¤ Contributing
- Submit issues or pull requests  
- Follow coding standards: black/isort/flake8  
- Include tests and documentation updates  

---

## ğŸ“ Contact
- Murci: +27 67 660 8432

